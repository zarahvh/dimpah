{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colonial-denial",
   "metadata": {},
   "source": [
    "In 2016, David Robinson's published a great analysis of Donald Trump's (http://varianceexplained.org/r/trump-tweets/). It got a lot of publicity and his collaboration with Julia Slige resulted in a new book and approach called tidytext (http://tidytextmining.com/). \n",
    "\n",
    "https://github.com/juliasilge/tidytext has become another package for advanced text analysis that has quickly gained a lot of support.\n",
    "\n",
    "The tidytext package allows to use tidytext principles (https://www.jstatsoft.org/article/view/v059i10) with unstructured data/text.\n",
    "\n",
    "Let's take a character vector with one element made of 3 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "later-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text = \"\"\"\n",
    "Using tidy data principles is important.\n",
    "In this package, we provide functions for tidy formats.\n",
    "The novels of Jane Austen can be so tidy!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-cabin",
   "metadata": {},
   "source": [
    "The dataset is not yet compatible with the tidy tools. The first step is to use unnest.\n",
    "\n",
    "### unnest_tokens function\n",
    "\n",
    "The unnest_token function splits a text column (input) into tokens (e.g. sentences, words, ngrams, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split = text.splitlines()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"text\": text_split,\n",
    "    \"line\": list(range(len(text_split)))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-berkeley",
   "metadata": {},
   "source": [
    "Next for the tidy text format.\n",
    "\n",
    "### The tidy text format\n",
    "\n",
    "Tidy text format is define as 'a table with one-term-per-row'. \n",
    "\n",
    "To tokenize into words (unigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "preliminary-replacement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tidy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>principles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>provide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>functions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tidy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>formats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tidy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line        word\n",
       "0     0         NaN\n",
       "1     1       using\n",
       "1     1        tidy\n",
       "1     1        data\n",
       "1     1  principles\n",
       "1     1          is\n",
       "1     1   important\n",
       "2     2          in\n",
       "2     2        this\n",
       "2     2     package\n",
       "2     2          we\n",
       "2     2     provide\n",
       "2     2   functions\n",
       "2     2         for\n",
       "2     2        tidy\n",
       "2     2     formats\n",
       "3     3         the\n",
       "3     3      novels\n",
       "3     3          of\n",
       "3     3        jane\n",
       "3     3      austen\n",
       "3     3         can\n",
       "3     3          be\n",
       "3     3          so\n",
       "3     3        tidy"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tidytext import unnest_tokens\n",
    "\n",
    "table = unnest_tokens(df, \"word\", \"text\")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-vessel",
   "metadata": {},
   "source": [
    "And tokenize into phrases (bigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigrams not available in pyhton function, is there a way around it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-optics",
   "metadata": {},
   "source": [
    "## Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hybrid-flour",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tidy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>principles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>provide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>functions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tidy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>formats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tidy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line        word\n",
       "0     0         NaN\n",
       "1     1       using\n",
       "1     1        tidy\n",
       "1     1        data\n",
       "1     1  principles\n",
       "1     1   important\n",
       "2     2     package\n",
       "2     2     provide\n",
       "2     2   functions\n",
       "2     2        tidy\n",
       "2     2     formats\n",
       "3     3      novels\n",
       "3     3        jane\n",
       "3     3      austen\n",
       "3     3        tidy"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = list(stopwords.words('english'))\n",
    "\n",
    "new_table = table[~table['word'].isin(stopwords)]\n",
    "new_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-pride",
   "metadata": {},
   "source": [
    "## Summarizing word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "manufactured-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count function using nltk too? is it available in tidytext?\n",
    "# bind_tfidf what does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "falling-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequencytable(df):\n",
    "    words = df['word']\n",
    "    freq_table = {}\n",
    "    for word in words:\n",
    "        if word in freq_table:\n",
    "            freq_table[word] += 1\n",
    "        else:\n",
    "            freq_table[word] = 1\n",
    "    return freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "identified-adolescent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: 1,\n",
       " 'using': 1,\n",
       " 'tidy': 3,\n",
       " 'data': 1,\n",
       " 'principles': 1,\n",
       " 'important': 1,\n",
       " 'package': 1,\n",
       " 'provide': 1,\n",
       " 'functions': 1,\n",
       " 'formats': 1,\n",
       " 'novels': 1,\n",
       " 'jane': 1,\n",
       " 'austen': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencytable(new_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-detector",
   "metadata": {},
   "source": [
    "## Case Study Gutenberg\n",
    "\n",
    "### Gutenbergr\n",
    "\n",
    "The gutenberg package (https://ropensci.org/tutorials/gutenbergr_tutorial.html) provides access to the Project Gutenberg collection. The package contains tools for downloading books and for finding works of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "nuclear-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "outside-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sherlock holmes\n",
    "\n",
    "# Retrieve the first 10 titles of Arthur Conan Doyle in the Gutenberg library.\n",
    "\n",
    "# how to get the books? either download them beforehand or use beautifulsoup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords and word count can be done using the previous functions again\n",
    "# ggplot in python\n",
    "# sentiment analysis --> again using NLTK?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
