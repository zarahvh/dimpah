{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Data from the Web\n",
    "\n",
    "## Social Networking Communities\n",
    "\n",
    "We have just discussed how clustering can be an effective tool to understand political behaviour. As an unsupervised learning technique it provides a new machine reading on party affiliations. Another popular application of clustering is detecting communities in social relationships.  Next we go through an example and dataset in Brett Lantz’s excellent book on Machine Learning (Lantz, B. (2013). Packt Publishing Ltd.). The dataset is discussed on pp. 279. It covers the relationships in a Social Networking Service (SNS). While this is a fairly early SNS dataset, it is freely available and offers similar kind of insights you can gain from my recent examples. \n",
    "\n",
    "This section also introduces you to the intersection of digital marketing techniques and sociological studies of online networks.\n",
    "\n",
    "Lantz explains that the dataset was compiled for sociological research on teenage identities at Notre Dame University. It represents a random sample of 30,000 US high school students who had profiles on a well-known SNS in 2006. At the time the data was collected, the SNS was a popular web destination for U.S. teenagers. Therefore, it is reasonable to assume that the profiles represent a fairly wide cross section of American adolescents in 2006. The data was sampled evenly across four high school graduation years (2006 through 2009) representing the senior, junior, second-year and freshman classes at the time of data collection. Then, the full texts of the SNS profiles were downloaded. Each teen's gender, age and number of SNS friends was recorded. \n",
    "\n",
    "A text-mining tool was used to divide the remaining SNS page content into words. From the top 500 words appearing across all pages, 36 words were chosen to represent five categories of interests, namely extracurricular activities, fashion, religion, romance and antisocial behaviour. The 36 words include terms such as football, sexy, kissed, bible, shopping, death, drugs, etc. The final dataset indicates, for each person, how many times each word appeared in the person's SNS profile. \n",
    "\n",
    "First we load the relevant packages and the dataset. Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "teens = pd.read_csv(\"data/snsdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the first couple of rows from the teens dataset. You know how ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gradyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>friends</th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>...</th>\n",
       "      <th>blonde</th>\n",
       "      <th>mall</th>\n",
       "      <th>shopping</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "      <th>drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gradyear gender   age  friends  basketball  football  soccer  \\\n",
       "0           1      2006      M  19.0        7           0         0       0   \n",
       "1           2      2006      F  19.0        0           0         1       0   \n",
       "2           3      2006      M  18.0       69           0         1       0   \n",
       "3           4      2006      F  19.0        0           0         0       0   \n",
       "4           5      2006    NaN  19.0       10           0         0       0   \n",
       "\n",
       "   softball  volleyball  ...  blonde  mall  shopping  clothes  hollister  \\\n",
       "0         0           0  ...       0     0         0        0          0   \n",
       "1         0           0  ...       0     1         0        0          0   \n",
       "2         0           0  ...       0     0         0        0          0   \n",
       "3         0           0  ...       0     0         0        0          0   \n",
       "4         0           0  ...       0     0         2        0          0   \n",
       "\n",
       "   abercrombie  die  death  drunk  drugs  \n",
       "0            0    0      0      0      0  \n",
       "1            0    0      0      0      0  \n",
       "2            0    0      1      0      0  \n",
       "3            0    0      0      0      0  \n",
       "4            0    0      0      1      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The teens dataset is now loaded into your environment. Take a close look and make sure you understand how it is produced.\n",
    "\n",
    "We can use the info() method to output some general information about the dataframe. Run `teens.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 41 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    30000 non-null  int64  \n",
      " 1   gradyear      30000 non-null  int64  \n",
      " 2   gender        27276 non-null  object \n",
      " 3   age           24914 non-null  float64\n",
      " 4   friends       30000 non-null  int64  \n",
      " 5   basketball    30000 non-null  int64  \n",
      " 6   football      30000 non-null  int64  \n",
      " 7   soccer        30000 non-null  int64  \n",
      " 8   softball      30000 non-null  int64  \n",
      " 9   volleyball    30000 non-null  int64  \n",
      " 10  swimming      30000 non-null  int64  \n",
      " 11  cheerleading  30000 non-null  int64  \n",
      " 12  baseball      30000 non-null  int64  \n",
      " 13  tennis        30000 non-null  int64  \n",
      " 14  sports        30000 non-null  int64  \n",
      " 15  cute          30000 non-null  int64  \n",
      " 16  sex           30000 non-null  int64  \n",
      " 17  sexy          30000 non-null  int64  \n",
      " 18  hot           30000 non-null  int64  \n",
      " 19  kissed        30000 non-null  int64  \n",
      " 20  dance         30000 non-null  int64  \n",
      " 21  band          30000 non-null  int64  \n",
      " 22  marching      30000 non-null  int64  \n",
      " 23  music         30000 non-null  int64  \n",
      " 24  rock          30000 non-null  int64  \n",
      " 25  god           30000 non-null  int64  \n",
      " 26  church        30000 non-null  int64  \n",
      " 27  jesus         30000 non-null  int64  \n",
      " 28  bible         30000 non-null  int64  \n",
      " 29  hair          30000 non-null  int64  \n",
      " 30  dress         30000 non-null  int64  \n",
      " 31  blonde        30000 non-null  int64  \n",
      " 32  mall          30000 non-null  int64  \n",
      " 33  shopping      30000 non-null  int64  \n",
      " 34  clothes       30000 non-null  int64  \n",
      " 35  hollister     30000 non-null  int64  \n",
      " 36  abercrombie   30000 non-null  int64  \n",
      " 37  die           30000 non-null  int64  \n",
      " 38  death         30000 non-null  int64  \n",
      " 39  drunk         30000 non-null  int64  \n",
      " 40  drugs         30000 non-null  int64  \n",
      "dtypes: float64(1), int64(39), object(1)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "teens.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of this lesson is centered on the issue of looking into real-life data on digital society. We have mentioned earlier that a common problem is that observations/records are missing in such data, which is indicated by the NaN value in Python - as you might remember. \n",
    "\n",
    "In the info printout, you can also see that the non-null count is lower for those columns that contain NaN values. Gender is one of them.\n",
    "\n",
    "Let's watch a quick video first how to deal with dirty data in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"90%\" height=\"90%\" controls src=\"img-videos/Session2.mp4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a lot of information. Let's go through this one step a time with the teens data.\n",
    "\n",
    "Print out the absolute non-null value counts for gender as well as the relative ones with:\n",
    "```\n",
    "print(teens['gender'].value_counts())\n",
    "print(teens['gender'].value_counts(normalize=True))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F    22054\n",
      "M     5222\n",
      "Name: gender, dtype: int64\n",
      "F    0.80855\n",
      "M    0.19145\n",
      "Name: gender, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(teens['gender'].value_counts())\n",
    "print(teens['gender'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With dropna set to False in value_counts, we can also see NaN index values. Try that ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F      22054\n",
       "M       5222\n",
       "NaN     2724\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens['gender'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But missing values are not our only problem. At least as common are misreported observations in real-life data. As an example, let’s look at the at the age distribution of the teens' age. You can do this in several ways but you should always print out maximum and minimum values. Run: `teens['age'].describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24914.000000\n",
       "mean        17.985791\n",
       "std          7.865982\n",
       "min          3.000000\n",
       "25%         16.000000\n",
       "50%         17.000000\n",
       "75%         18.000000\n",
       "max        107.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few strange records here. Teens can have a minimum age of less than 4 and a maximum age of over 100! These cannot be considered teenagers. \n",
    "\n",
    "As a rule of thumb, let’s assume teenagers are between 13 and 19 years old. Let’s mark all other teens' age entries as invalid. We say that invalid entries should have a NaN value. Set this, please, by typing in `teens.loc[(teens['age'] < 13) | (teens['age'] >= 20), 'age'] = np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "teens.loc[(teens['age'] < 13) | (teens['age'] >= 20), 'age'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our data cleaning process is to replace NaN values. Of course, we could simply remove all rows/observations, for which we have null entries. We did this effectively in the senate example. But then there was only one row that contained null values. In the SNS example, we would lose too many rows with such a brute-force approach. So, let’s try and fill the null values with estimated values. \n",
    "\n",
    "Let’s start with the gender and replace null values by creating new columns for male and females. \n",
    "\n",
    "To this end, we first create a new column to record all the female teenagers. Create a new column 'female' that is set to 1 if the teenager is female and 0 otherwise. Run `teens.loc[(teens['gender'] == 'F') & (teens['gender'].notna()), 'female'] = 1` to set the female column to 1 for females. notna() selects all rows that are not NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "teens.loc[(teens['gender'] == 'F') & (teens['gender'].notna()), 'female'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you set the female column to 0 for males? You just need to change one letter ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teens.loc[(teens['gender'] == 'M') & (teens['gender'].notna()), 'female'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create another column for the null values in gender we want to call no_gender. Set this to 1 if there is no gender recorded and otherwise to 0. \n",
    "\n",
    "This process is called dummy-coding btw. This is typical to community analysis. A dummy variable is a numerical variable used in the analysis to represent subgroups – in our case males, females and others. In research design, a dummy variable is often used to distinguish different groups to address them differently. By creating a separate column per gender entry, we can compute clusters for separate gender communities. \n",
    "\n",
    "Check out dummy-coding on the web. Can you find easier ways to do this in Pandas?\n",
    "\n",
    "Run \n",
    "```\n",
    "teens.loc[teens['gender'].notna(), 'no_gender'] = 0\n",
    "teens.loc[teens['gender'].isna(), 'no_gender'] = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "teens.loc[teens['gender'].notna(), 'no_gender'] = 0\n",
    "teens.loc[teens['gender'].isna(), 'no_gender'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we have the original column, a new column called female, which contains information about whether the teen is female or not (male) and a new column with information about whether the gender value is missing. Using this column we could, for instance, check with clustering whether certain communities have a tendency not to record their gender values. How? \n",
    "\n",
    "Check out the changes with teens.head(). You have to scroll all the way to the right to find the new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gradyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>friends</th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>...</th>\n",
       "      <th>shopping</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "      <th>drugs</th>\n",
       "      <th>female</th>\n",
       "      <th>no_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>18.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>18.0</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  gradyear gender   age  friends  basketball  football  soccer  \\\n",
       "0            1      2006      M  19.0        7           0         0       0   \n",
       "1            2      2006      F  19.0        0           0         1       0   \n",
       "2            3      2006      M  18.0       69           0         1       0   \n",
       "3            4      2006      F  19.0        0           0         0       0   \n",
       "4            5      2006    NaN  19.0       10           0         0       0   \n",
       "5            6      2006      F   NaN      142           0         0       0   \n",
       "6            7      2006      F  19.0       72           0         0       0   \n",
       "7            8      2006      M  18.0       17           0         0       0   \n",
       "8            9      2006      F  19.0       52           0         0       0   \n",
       "9           10      2006      F  19.0       39           0         0       0   \n",
       "10          11      2006      F  19.0        8           0         0       0   \n",
       "11          12      2006      F  19.0       21           0         1       0   \n",
       "12          13      2006      F  18.0       87           0         0       0   \n",
       "13          14      2006    NaN   NaN        0           0         0       0   \n",
       "14          15      2006      F  18.0        0           0         0       0   \n",
       "15          16      2006    NaN   NaN        0           0         0       0   \n",
       "16          17      2006    NaN   NaN      135           0         0       0   \n",
       "17          18      2006      F  19.0       26           0         0       2   \n",
       "18          19      2006      F  17.0       27           1         1       0   \n",
       "19          20      2006      F  18.0      123           0         0       0   \n",
       "\n",
       "    softball  volleyball  ...  shopping  clothes  hollister  abercrombie  die  \\\n",
       "0          0           0  ...         0        0          0            0    0   \n",
       "1          0           0  ...         0        0          0            0    0   \n",
       "2          0           0  ...         0        0          0            0    0   \n",
       "3          0           0  ...         0        0          0            0    0   \n",
       "4          0           0  ...         2        0          0            0    0   \n",
       "5          0           0  ...         1        0          0            0    0   \n",
       "6          0           0  ...         0        0          2            0    0   \n",
       "7          1           0  ...         0        0          0            0    0   \n",
       "8          0           0  ...         0        0          0            0    0   \n",
       "9          0           0  ...         1        0          0            0    0   \n",
       "10         0           0  ...         0        0          0            0    0   \n",
       "11         0           0  ...         0        0          0            0    0   \n",
       "12         0           0  ...         0        0          0            0    0   \n",
       "13         0           0  ...         0        0          0            0    0   \n",
       "14         0           0  ...         0        1          0            0    0   \n",
       "15         0           0  ...         0        0          0            0    0   \n",
       "16         0           0  ...         0        0          0            0    0   \n",
       "17         0           0  ...         0        0          0            0    0   \n",
       "18         0           0  ...         0        0          0            0    0   \n",
       "19         0           0  ...         2        0          1            1    0   \n",
       "\n",
       "    death  drunk  drugs  female  no_gender  \n",
       "0       0      0      0     0.0        0.0  \n",
       "1       0      0      0     1.0        0.0  \n",
       "2       1      0      0     0.0        0.0  \n",
       "3       0      0      0     1.0        0.0  \n",
       "4       0      1      1     NaN        1.0  \n",
       "5       0      1      0     1.0        0.0  \n",
       "6       0      0      0     1.0        0.0  \n",
       "7       0      0      0     0.0        0.0  \n",
       "8       0      0      0     1.0        0.0  \n",
       "9       0      0      0     1.0        0.0  \n",
       "10      0      0      0     1.0        0.0  \n",
       "11      0      0      0     1.0        0.0  \n",
       "12      0      0      0     1.0        0.0  \n",
       "13      0      0      0     NaN        1.0  \n",
       "14      0      0      0     1.0        0.0  \n",
       "15      0      0      0     NaN        1.0  \n",
       "16      0      0      0     NaN        1.0  \n",
       "17      0      0      0     1.0        0.0  \n",
       "18      0      0      0     1.0        0.0  \n",
       "19      0      0      0     1.0        0.0  \n",
       "\n",
       "[20 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very easy now to calculate the number of teenagers where we do not have gender entries for. How? Remember sum()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2724.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens['no_gender'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you find that there are 2724.\n",
    "\n",
    "The age column is next. \n",
    "\n",
    "Can you find the average age and take care that null values are discounted? Tip: run Pandas' mean and set skipna = True: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.223233030090974"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens['age'].mean(skipna = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if you set skipna to False?\n",
    "\n",
    "A good strategy to overwrite missing age values would be to use the average age value and assign it to all of the missing ones. This process is called mean-imputation and is employed frequently. Pandas has some real strengths here. Check out https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html.\n",
    "\n",
    "Pandas makes you life very easy with its fillna function. Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25    17.000000\n",
       "0.50    17.223233\n",
       "0.75    18.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keep cell\n",
    "teens['age'].fillna(teens['age'].mean()).quantile([.25, .5, .75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further improve this with some good old-fashioned human intelligence.\n",
    "\n",
    "We feel confident that we can do better than just the mean, because we know the graduation year, too. This is the year our teens are supposed to graduate. It seems a reasonable assumption that those teenagers with an earlier graduation year should be older than those for whom graduation is further away. \n",
    "\n",
    "We can easily find this out by running the mean function for each graduation year group separately. Type in `teens[['gradyear', 'age']].groupby(['gradyear']).mean()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradyear</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>18.599801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>17.685516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>16.762584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>15.823470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age\n",
       "gradyear           \n",
       "2006      18.599801\n",
       "2007      17.685516\n",
       "2008      16.762584\n",
       "2009      15.823470"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens[['gradyear', 'age']].groupby(['gradyear']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment and look at groupby() as it is essential knowledge to deal with Pandas: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html. It is at the heart of the split-apply-combine paradigm that will keep us busy for the rest of this session: https://pandas.pydata.org/docs/user_guide/groupby.html. Take a close read and you will see that we will cover all its elements throughout the session today. Groupby allows you to to 'split' data into distinct groups. This is often done with the intention to then 'apply' functions afterwards like in our case mean(). This works amazingly well but requires lots of practice in my exeperience. So, let's move on.\n",
    "\n",
    "According to our last output, our suspicion has proven right. There is a significant difference in the average ages depending on the graduation year. Let’s use this knowledge and update missing values in the age group depending on the graduation year. To this end, you actually have to do a lot of Pandas labour, which demonstrates that 80% of the work of a data scientist lies in working with data. But I am sure you know this by now.\n",
    "\n",
    "You can, e.g., proceed with the following strategy:\n",
    "Create first a temporary dataset with the results from the above group_by call. Then merge this new dataset with teens and replace the null values of teens.age with the ones from the temporary dataset.\n",
    "\n",
    "Create the temporary dataset first with `ave_age = teens[['gradyear', 'age']].groupby(['gradyear'], as_index=False).mean()`. Also print out ave_age. It should be a data frame of three rows. \n",
    "\n",
    "Wondering about as_index=False? Check out https://pandas.pydata.org/docs/user_guide/groupby.html. We simply do not want to create a new index from the groupby argument gradyear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gradyear</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>18.599801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>17.685516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>16.762584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>15.823470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gradyear        age\n",
       "0      2006  18.599801\n",
       "1      2007  17.685516\n",
       "2      2008  16.762584\n",
       "3      2009  15.823470"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_age = teens[['gradyear', 'age']].groupby(['gradyear'], as_index=False).mean()\n",
    "ave_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the teens age columns but make sure that in the end you have not added additional columns. First you need to merge teens and ave_age on gradyear. Run `teens = pd.merge(teens, ave_age, on=['gradyear'])`. Also print out the first few columns of teens.\n",
    "\n",
    "Merge is another powerful command to learn about. It's part of the Merge, join, concatenate and compare group of command - some of which we have already met: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html. If you happen to know database languages, you will know everything about it. Merge() combines two data frames on common columns - in our case gradyear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gradyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_x</th>\n",
       "      <th>friends</th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>...</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "      <th>drugs</th>\n",
       "      <th>female</th>\n",
       "      <th>no_gender</th>\n",
       "      <th>age_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.599801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.599801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.599801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.599801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.599801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gradyear gender  age_x  friends  basketball  football  soccer  \\\n",
       "0           1      2006      M   19.0        7           0         0       0   \n",
       "1           2      2006      F   19.0        0           0         1       0   \n",
       "2           3      2006      M   18.0       69           0         1       0   \n",
       "3           4      2006      F   19.0        0           0         0       0   \n",
       "4           5      2006    NaN   19.0       10           0         0       0   \n",
       "\n",
       "   softball  volleyball  ...  clothes  hollister  abercrombie  die  death  \\\n",
       "0         0           0  ...        0          0            0    0      0   \n",
       "1         0           0  ...        0          0            0    0      0   \n",
       "2         0           0  ...        0          0            0    0      1   \n",
       "3         0           0  ...        0          0            0    0      0   \n",
       "4         0           0  ...        0          0            0    0      0   \n",
       "\n",
       "   drunk  drugs  female  no_gender      age_y  \n",
       "0      0      0     0.0        0.0  18.599801  \n",
       "1      0      0     1.0        0.0  18.599801  \n",
       "2      0      0     0.0        0.0  18.599801  \n",
       "3      0      0     1.0        0.0  18.599801  \n",
       "4      1      1     NaN        1.0  18.599801  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens = pd.merge(teens, ave_age, on=['gradyear'])\n",
    "teens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some scrolling, you should now see two age columns. age_x is the original one from teens, while age_y is the estimated value based on the gradyear. Now, we want to replace the age_x (the original value) with age_y if age_x is NaN. Run `teens.loc[(teens['age_x'].isna()), 'age_x'] = teens['age_y']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "teens.loc[(teens['age_x'].isna()), 'age_x'] = teens['age_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we only need to so some cleaning up. Give age_x its old name age back and drop age_y, which we don't need anymore. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep cell\n",
    "teens.rename(columns={'age_x': 'age'}, inplace=True)\n",
    "teens.drop('age_y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `teens.info()` to see that the age column does not contain NaNs anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 0 to 29999\n",
      "Data columns (total 43 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    30000 non-null  int64  \n",
      " 1   gradyear      30000 non-null  int64  \n",
      " 2   gender        27276 non-null  object \n",
      " 3   age           30000 non-null  float64\n",
      " 4   friends       30000 non-null  int64  \n",
      " 5   basketball    30000 non-null  int64  \n",
      " 6   football      30000 non-null  int64  \n",
      " 7   soccer        30000 non-null  int64  \n",
      " 8   softball      30000 non-null  int64  \n",
      " 9   volleyball    30000 non-null  int64  \n",
      " 10  swimming      30000 non-null  int64  \n",
      " 11  cheerleading  30000 non-null  int64  \n",
      " 12  baseball      30000 non-null  int64  \n",
      " 13  tennis        30000 non-null  int64  \n",
      " 14  sports        30000 non-null  int64  \n",
      " 15  cute          30000 non-null  int64  \n",
      " 16  sex           30000 non-null  int64  \n",
      " 17  sexy          30000 non-null  int64  \n",
      " 18  hot           30000 non-null  int64  \n",
      " 19  kissed        30000 non-null  int64  \n",
      " 20  dance         30000 non-null  int64  \n",
      " 21  band          30000 non-null  int64  \n",
      " 22  marching      30000 non-null  int64  \n",
      " 23  music         30000 non-null  int64  \n",
      " 24  rock          30000 non-null  int64  \n",
      " 25  god           30000 non-null  int64  \n",
      " 26  church        30000 non-null  int64  \n",
      " 27  jesus         30000 non-null  int64  \n",
      " 28  bible         30000 non-null  int64  \n",
      " 29  hair          30000 non-null  int64  \n",
      " 30  dress         30000 non-null  int64  \n",
      " 31  blonde        30000 non-null  int64  \n",
      " 32  mall          30000 non-null  int64  \n",
      " 33  shopping      30000 non-null  int64  \n",
      " 34  clothes       30000 non-null  int64  \n",
      " 35  hollister     30000 non-null  int64  \n",
      " 36  abercrombie   30000 non-null  int64  \n",
      " 37  die           30000 non-null  int64  \n",
      " 38  death         30000 non-null  int64  \n",
      " 39  drunk         30000 non-null  int64  \n",
      " 40  drugs         30000 non-null  int64  \n",
      " 41  female        27276 non-null  float64\n",
      " 42  no_gender     30000 non-null  float64\n",
      "dtypes: float64(3), int64(39), object(1)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "teens.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out new ave_age with `teens['age'].mean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.21784283910326"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all quite advanced stuff but as long as you remember the kind of steps we have taken you should be able to impute one column's missing values by using another column as a reference. In our case, we use our knowledge that age is dependent on gradyear to find the missing values. Please, take some time to review the steps.\n",
    "\n",
    "Let’s take a look at the resulting age column with `teens['age'].describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30000.000000\n",
       "mean        17.217843\n",
       "std          1.153788\n",
       "min         13.000000\n",
       "25%         16.000000\n",
       "50%         17.000000\n",
       "75%         18.000000\n",
       "max         19.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better. We have now learned how to delete missing values completely or impute them using a background knowledge. \n",
    "\n",
    "After we have dealt with the missing records, I think we are ready to cluster again. We will use our trusted k-means without actually referring to either age nor gender. Sorry! But it was good that you learned how to deal with missing values and we will use them later. \n",
    "\n",
    "Just like in the US Senate example, we need to first understand, what we are trying to cluster. In the Senate example, we clustered voting behaviour. Now, it will be interests, which we can get from the columns 5 to 40 of the teens data frame. This time we select them by number as there is no clever way of selecting them by expression as for the Senate data.\n",
    "\n",
    "Please create the interests dataframe by selecting columns 5 to 40 from teens with `interests = teens.iloc[:,5:40]`. Also, print out the first few rows of interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>swimming</th>\n",
       "      <th>cheerleading</th>\n",
       "      <th>baseball</th>\n",
       "      <th>tennis</th>\n",
       "      <th>sports</th>\n",
       "      <th>...</th>\n",
       "      <th>dress</th>\n",
       "      <th>blonde</th>\n",
       "      <th>mall</th>\n",
       "      <th>shopping</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   basketball  football  soccer  softball  volleyball  swimming  cheerleading  \\\n",
       "0           0         0       0         0           0         0             0   \n",
       "1           0         1       0         0           0         0             0   \n",
       "2           0         1       0         0           0         0             0   \n",
       "3           0         0       0         0           0         0             0   \n",
       "4           0         0       0         0           0         0             0   \n",
       "\n",
       "   baseball  tennis  sports  ...  dress  blonde  mall  shopping  clothes  \\\n",
       "0         0       0       0  ...      0       0     0         0        0   \n",
       "1         0       0       0  ...      4       0     1         0        0   \n",
       "2         0       0       0  ...      0       0     0         0        0   \n",
       "3         0       0       0  ...      0       0     0         0        0   \n",
       "4         0       0       0  ...      0       0     0         2        0   \n",
       "\n",
       "   hollister  abercrombie  die  death  drunk  \n",
       "0          0            0    0      0      0  \n",
       "1          0            0    0      0      0  \n",
       "2          0            0    0      1      0  \n",
       "3          0            0    0      0      0  \n",
       "4          0            0    0      0      1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interests = teens.iloc[:,5:40]\n",
    "interests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not mention this before, because it was not necessary but k-means is very sensitive to input of varying size, length, etc. It was not necessary to focus on this in the previous example, because all the voting behaviour was in the range of 0 to 1. Now, we have interests of very different ranges. The interests are simply based on how many times a keyword appears in teenagers' social networking contributions.\n",
    "\n",
    "Since k-means is based on calculating distances between data points and their centroids, it will be strongly influenced by the magnitudes of the variables we cluster. Think about if for a moment! Just imagine one column having values running from 1 to 10 and another from 1 to 1000. How could we compare distances between them? \n",
    "\n",
    "We therefore need to scale the value so that they all fall into the same range. To this end, Python has the scale function in scipy.stats, which centres values around their mean. Using the apply function, we can tell Python to scale all interests values. apply is an alternative way to loop over values in a column and apply a function: https://www.datacamp.com/community/tutorials/pandas-apply.\n",
    "\n",
    "Run `from scipy.stats import zscore` to import zscore, which is very popular in data analysis for standardisation: https://www.statisticshowto.com/probability-and-statistics/z-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply zscore and assign the results to a new dataframe interests_z with `interests_z = interests.apply(zscore)`. Finally, print out the first few columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>swimming</th>\n",
       "      <th>cheerleading</th>\n",
       "      <th>baseball</th>\n",
       "      <th>tennis</th>\n",
       "      <th>sports</th>\n",
       "      <th>...</th>\n",
       "      <th>dress</th>\n",
       "      <th>blonde</th>\n",
       "      <th>mall</th>\n",
       "      <th>shopping</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.332217</td>\n",
       "      <td>-0.357697</td>\n",
       "      <td>-0.242874</td>\n",
       "      <td>-0.217928</td>\n",
       "      <td>-0.22367</td>\n",
       "      <td>-0.259971</td>\n",
       "      <td>-0.207327</td>\n",
       "      <td>-0.201131</td>\n",
       "      <td>-0.168939</td>\n",
       "      <td>-0.297123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246906</td>\n",
       "      <td>-0.050937</td>\n",
       "      <td>-0.369915</td>\n",
       "      <td>-0.487314</td>\n",
       "      <td>-0.314198</td>\n",
       "      <td>-0.201476</td>\n",
       "      <td>-0.183032</td>\n",
       "      <td>-0.294793</td>\n",
       "      <td>-0.261530</td>\n",
       "      <td>-0.220403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.332217</td>\n",
       "      <td>1.060049</td>\n",
       "      <td>-0.242874</td>\n",
       "      <td>-0.217928</td>\n",
       "      <td>-0.22367</td>\n",
       "      <td>-0.259971</td>\n",
       "      <td>-0.207327</td>\n",
       "      <td>-0.201131</td>\n",
       "      <td>-0.168939</td>\n",
       "      <td>-0.297123</td>\n",
       "      <td>...</td>\n",
       "      <td>8.653277</td>\n",
       "      <td>-0.050937</td>\n",
       "      <td>1.067392</td>\n",
       "      <td>-0.487314</td>\n",
       "      <td>-0.314198</td>\n",
       "      <td>-0.201476</td>\n",
       "      <td>-0.183032</td>\n",
       "      <td>-0.294793</td>\n",
       "      <td>-0.261530</td>\n",
       "      <td>-0.220403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.332217</td>\n",
       "      <td>1.060049</td>\n",
       "      <td>-0.242874</td>\n",
       "      <td>-0.217928</td>\n",
       "      <td>-0.22367</td>\n",
       "      <td>-0.259971</td>\n",
       "      <td>-0.207327</td>\n",
       "      <td>-0.201131</td>\n",
       "      <td>-0.168939</td>\n",
       "      <td>-0.297123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246906</td>\n",
       "      <td>-0.050937</td>\n",
       "      <td>-0.369915</td>\n",
       "      <td>-0.487314</td>\n",
       "      <td>-0.314198</td>\n",
       "      <td>-0.201476</td>\n",
       "      <td>-0.183032</td>\n",
       "      <td>-0.294793</td>\n",
       "      <td>2.027908</td>\n",
       "      <td>-0.220403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.332217</td>\n",
       "      <td>-0.357697</td>\n",
       "      <td>-0.242874</td>\n",
       "      <td>-0.217928</td>\n",
       "      <td>-0.22367</td>\n",
       "      <td>-0.259971</td>\n",
       "      <td>-0.207327</td>\n",
       "      <td>-0.201131</td>\n",
       "      <td>-0.168939</td>\n",
       "      <td>-0.297123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246906</td>\n",
       "      <td>-0.050937</td>\n",
       "      <td>-0.369915</td>\n",
       "      <td>-0.487314</td>\n",
       "      <td>-0.314198</td>\n",
       "      <td>-0.201476</td>\n",
       "      <td>-0.183032</td>\n",
       "      <td>-0.294793</td>\n",
       "      <td>-0.261530</td>\n",
       "      <td>-0.220403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.332217</td>\n",
       "      <td>-0.357697</td>\n",
       "      <td>-0.242874</td>\n",
       "      <td>-0.217928</td>\n",
       "      <td>-0.22367</td>\n",
       "      <td>-0.259971</td>\n",
       "      <td>-0.207327</td>\n",
       "      <td>-0.201131</td>\n",
       "      <td>-0.168939</td>\n",
       "      <td>-0.297123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246906</td>\n",
       "      <td>-0.050937</td>\n",
       "      <td>-0.369915</td>\n",
       "      <td>2.273673</td>\n",
       "      <td>-0.314198</td>\n",
       "      <td>-0.201476</td>\n",
       "      <td>-0.183032</td>\n",
       "      <td>-0.294793</td>\n",
       "      <td>-0.261530</td>\n",
       "      <td>2.285122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   basketball  football    soccer  softball  volleyball  swimming  \\\n",
       "0   -0.332217 -0.357697 -0.242874 -0.217928    -0.22367 -0.259971   \n",
       "1   -0.332217  1.060049 -0.242874 -0.217928    -0.22367 -0.259971   \n",
       "2   -0.332217  1.060049 -0.242874 -0.217928    -0.22367 -0.259971   \n",
       "3   -0.332217 -0.357697 -0.242874 -0.217928    -0.22367 -0.259971   \n",
       "4   -0.332217 -0.357697 -0.242874 -0.217928    -0.22367 -0.259971   \n",
       "\n",
       "   cheerleading  baseball    tennis    sports  ...     dress    blonde  \\\n",
       "0     -0.207327 -0.201131 -0.168939 -0.297123  ... -0.246906 -0.050937   \n",
       "1     -0.207327 -0.201131 -0.168939 -0.297123  ...  8.653277 -0.050937   \n",
       "2     -0.207327 -0.201131 -0.168939 -0.297123  ... -0.246906 -0.050937   \n",
       "3     -0.207327 -0.201131 -0.168939 -0.297123  ... -0.246906 -0.050937   \n",
       "4     -0.207327 -0.201131 -0.168939 -0.297123  ... -0.246906 -0.050937   \n",
       "\n",
       "       mall  shopping   clothes  hollister  abercrombie       die     death  \\\n",
       "0 -0.369915 -0.487314 -0.314198  -0.201476    -0.183032 -0.294793 -0.261530   \n",
       "1  1.067392 -0.487314 -0.314198  -0.201476    -0.183032 -0.294793 -0.261530   \n",
       "2 -0.369915 -0.487314 -0.314198  -0.201476    -0.183032 -0.294793  2.027908   \n",
       "3 -0.369915 -0.487314 -0.314198  -0.201476    -0.183032 -0.294793 -0.261530   \n",
       "4 -0.369915  2.273673 -0.314198  -0.201476    -0.183032 -0.294793 -0.261530   \n",
       "\n",
       "      drunk  \n",
       "0 -0.220403  \n",
       "1 -0.220403  \n",
       "2 -0.220403  \n",
       "3 -0.220403  \n",
       "4  2.285122  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interests_z = interests.apply(zscore)\n",
    "interests_z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clearly normalized around the means of the various columns - by the distance of the standard deviation.\n",
    "\n",
    "### Clustering\n",
    "\n",
    "Now we cluster again and start by importing KMeans. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep cell\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide 5 clusters is enough and assign k = 5. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "#Keep cell\n",
    "\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to cluster. Create and fit teen_clusters the way you know. It is just a copy and paste job from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teen_clusters = KMeans(n_clusters  = k) \n",
    "teen_clusters.fit(interests_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s investigate the size of the clusters with .labels_ and np.bincount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21555,   606,  6065,   903,   871])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(teen_clusters.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have noticed very different results depending on the kmeans results. I suggest to rerun kmeans a couple of times until you see a distribution that looks ok. You want to especially avoid clusters of only one 1 item. This would be the time to determine the optimal k with the elbow method, but we don't want to to that right now and move on.\n",
    "\n",
    "We can also look at the centroids/centres with teen_clusters.cluster_centers_. You learned earlier how to pretty-print this in a data frame. Run:\n",
    "```\n",
    "interests_centroids = pd.DataFrame(teen_clusters.cluster_centers_, columns=interests_z.columns)\n",
    "interests_centroids\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>swimming</th>\n",
       "      <th>cheerleading</th>\n",
       "      <th>baseball</th>\n",
       "      <th>tennis</th>\n",
       "      <th>sports</th>\n",
       "      <th>...</th>\n",
       "      <th>dress</th>\n",
       "      <th>blonde</th>\n",
       "      <th>mall</th>\n",
       "      <th>shopping</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.165700</td>\n",
       "      <td>-0.163319</td>\n",
       "      <td>-0.089500</td>\n",
       "      <td>-0.114934</td>\n",
       "      <td>-0.117670</td>\n",
       "      <td>-0.107491</td>\n",
       "      <td>-0.115132</td>\n",
       "      <td>-0.108819</td>\n",
       "      <td>-0.050377</td>\n",
       "      <td>-0.130277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143154</td>\n",
       "      <td>-0.029007</td>\n",
       "      <td>-0.189193</td>\n",
       "      <td>-0.232519</td>\n",
       "      <td>-0.189328</td>\n",
       "      <td>-0.156387</td>\n",
       "      <td>-0.148178</td>\n",
       "      <td>-0.092341</td>\n",
       "      <td>-0.082756</td>\n",
       "      <td>-0.084042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098441</td>\n",
       "      <td>0.058736</td>\n",
       "      <td>-0.100744</td>\n",
       "      <td>-0.026073</td>\n",
       "      <td>-0.063793</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>-0.104658</td>\n",
       "      <td>-0.122057</td>\n",
       "      <td>0.038548</td>\n",
       "      <td>-0.097453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083546</td>\n",
       "      <td>-0.012705</td>\n",
       "      <td>-0.071069</td>\n",
       "      <td>-0.029428</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>-0.168166</td>\n",
       "      <td>-0.141711</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.052040</td>\n",
       "      <td>-0.083963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.507589</td>\n",
       "      <td>0.475845</td>\n",
       "      <td>0.287252</td>\n",
       "      <td>0.367224</td>\n",
       "      <td>0.378010</td>\n",
       "      <td>0.303391</td>\n",
       "      <td>0.335872</td>\n",
       "      <td>0.341953</td>\n",
       "      <td>0.135555</td>\n",
       "      <td>0.328140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389031</td>\n",
       "      <td>0.034689</td>\n",
       "      <td>0.507584</td>\n",
       "      <td>0.669051</td>\n",
       "      <td>0.382935</td>\n",
       "      <td>-0.052228</td>\n",
       "      <td>-0.075133</td>\n",
       "      <td>0.060193</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.031513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.456345</td>\n",
       "      <td>0.441453</td>\n",
       "      <td>0.173671</td>\n",
       "      <td>0.222229</td>\n",
       "      <td>0.129358</td>\n",
       "      <td>0.266983</td>\n",
       "      <td>0.188853</td>\n",
       "      <td>0.352879</td>\n",
       "      <td>0.137397</td>\n",
       "      <td>0.873599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598266</td>\n",
       "      <td>0.407474</td>\n",
       "      <td>0.559639</td>\n",
       "      <td>0.318356</td>\n",
       "      <td>1.384543</td>\n",
       "      <td>0.197711</td>\n",
       "      <td>0.292339</td>\n",
       "      <td>1.740926</td>\n",
       "      <td>1.001084</td>\n",
       "      <td>1.794006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.160015</td>\n",
       "      <td>0.228283</td>\n",
       "      <td>0.103857</td>\n",
       "      <td>0.073874</td>\n",
       "      <td>0.188975</td>\n",
       "      <td>0.253031</td>\n",
       "      <td>0.386454</td>\n",
       "      <td>0.029935</td>\n",
       "      <td>0.133105</td>\n",
       "      <td>0.100143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154164</td>\n",
       "      <td>0.062557</td>\n",
       "      <td>0.615242</td>\n",
       "      <td>0.783818</td>\n",
       "      <td>0.577309</td>\n",
       "      <td>4.145632</td>\n",
       "      <td>3.985539</td>\n",
       "      <td>0.054507</td>\n",
       "      <td>0.116976</td>\n",
       "      <td>0.058628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   basketball  football    soccer  softball  volleyball  swimming  \\\n",
       "0   -0.165700 -0.163319 -0.089500 -0.114934   -0.117670 -0.107491   \n",
       "1   -0.098441  0.058736 -0.100744 -0.026073   -0.063793  0.024111   \n",
       "2    0.507589  0.475845  0.287252  0.367224    0.378010  0.303391   \n",
       "3    0.456345  0.441453  0.173671  0.222229    0.129358  0.266983   \n",
       "4    0.160015  0.228283  0.103857  0.073874    0.188975  0.253031   \n",
       "\n",
       "   cheerleading  baseball    tennis    sports  ...     dress    blonde  \\\n",
       "0     -0.115132 -0.108819 -0.050377 -0.130277  ... -0.143154 -0.029007   \n",
       "1     -0.104658 -0.122057  0.038548 -0.097453  ...  0.083546 -0.012705   \n",
       "2      0.335872  0.341953  0.135555  0.328140  ...  0.389031  0.034689   \n",
       "3      0.188853  0.352879  0.137397  0.873599  ...  0.598266  0.407474   \n",
       "4      0.386454  0.029935  0.133105  0.100143  ...  0.154164  0.062557   \n",
       "\n",
       "       mall  shopping   clothes  hollister  abercrombie       die     death  \\\n",
       "0 -0.189193 -0.232519 -0.189328  -0.156387    -0.148178 -0.092341 -0.082756   \n",
       "1 -0.071069 -0.029428  0.007014  -0.168166    -0.141711  0.009078  0.052040   \n",
       "2  0.507584  0.669051  0.382935  -0.052228    -0.075133  0.060193  0.122999   \n",
       "3  0.559639  0.318356  1.384543   0.197711     0.292339  1.740926  1.001084   \n",
       "4  0.615242  0.783818  0.577309   4.145632     3.985539  0.054507  0.116976   \n",
       "\n",
       "      drunk  \n",
       "0 -0.084042  \n",
       "1 -0.083963  \n",
       "2  0.031513  \n",
       "3  1.794006  \n",
       "4  0.058628  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interests_centroids = pd.DataFrame(teen_clusters.cluster_centers_, columns=interests_z.columns)\n",
    "interests_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to detect clusters is to find thr maximum values in the columns. Try it by using the idxmax() function from Pandas: `interests_centroids.idxmax()`. Check out its documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basketball      2\n",
       "football        2\n",
       "soccer          2\n",
       "softball        2\n",
       "volleyball      2\n",
       "swimming        2\n",
       "cheerleading    4\n",
       "baseball        3\n",
       "tennis          3\n",
       "sports          3\n",
       "cute            3\n",
       "sex             3\n",
       "sexy            3\n",
       "hot             4\n",
       "kissed          3\n",
       "dance           3\n",
       "band            1\n",
       "marching        1\n",
       "music           3\n",
       "rock            3\n",
       "god             3\n",
       "church          2\n",
       "jesus           2\n",
       "bible           2\n",
       "hair            3\n",
       "dress           3\n",
       "blonde          3\n",
       "mall            4\n",
       "shopping        4\n",
       "clothes         3\n",
       "hollister       4\n",
       "abercrombie     4\n",
       "die             3\n",
       "death           3\n",
       "drunk           3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interests_centroids.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, your results look similar to the table from Lantz (2013) on p. 288: \n",
    "\n",
    "![title](img-videos/teen-clusters.jpg)\n",
    "\n",
    "Do the names of the clusters make sense to you? Do you remember all those teenage movies you watched?\n",
    "\n",
    "Next, let’s continue with another type of analysis. Let’s first assign each teen to a cluster, as we did before in the voting example for the senators. Please, add a column called 'cluster' to the teen data frame with `teens['cluster'] = np.array(teen_clusters.labels_)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "teens['cluster'] = np.array(teen_clusters.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the teen data frame with head(). All the way to the right, you can find the cluster assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gradyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>friends</th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>...</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "      <th>drugs</th>\n",
       "      <th>female</th>\n",
       "      <th>no_gender</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gradyear gender   age  friends  basketball  football  soccer  \\\n",
       "0           1      2006      M  19.0        7           0         0       0   \n",
       "1           2      2006      F  19.0        0           0         1       0   \n",
       "2           3      2006      M  18.0       69           0         1       0   \n",
       "3           4      2006      F  19.0        0           0         0       0   \n",
       "4           5      2006    NaN  19.0       10           0         0       0   \n",
       "\n",
       "   softball  volleyball  ...  clothes  hollister  abercrombie  die  death  \\\n",
       "0         0           0  ...        0          0            0    0      0   \n",
       "1         0           0  ...        0          0            0    0      0   \n",
       "2         0           0  ...        0          0            0    0      1   \n",
       "3         0           0  ...        0          0            0    0      0   \n",
       "4         0           0  ...        0          0            0    0      0   \n",
       "\n",
       "   drunk  drugs  female  no_gender  cluster  \n",
       "0      0      0     0.0        0.0        0  \n",
       "1      0      0     1.0        0.0        2  \n",
       "2      0      0     0.0        0.0        0  \n",
       "3      0      0     1.0        0.0        0  \n",
       "4      1      1     NaN        1.0        3  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the first 5 teens and only the columns 'cluster', 'gender', 'age' and 'friends'. I hope you remember how this works. How do we select the first 5 rows? How do we select the columns? Tip: loc is the function you are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster gender   age  friends\n",
       "0        0      M  19.0        7\n",
       "1        2      F  19.0        0\n",
       "2        0      M  18.0       69\n",
       "3        0      F  19.0        0\n",
       "4        3    NaN  19.0       10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens.loc[:4, ['cluster', 'gender', 'age', 'friends']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have learned earlier how to group by particular interests, let’s aggregate the teens' features using the clusters. \n",
    "\n",
    "Print out the average ages per cluster. Do you remember how this works? Tip: Replace gradyear with cluster and you are ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.275689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17.377248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17.068167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17.087143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16.853126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster        age\n",
       "0        0  17.275689\n",
       "1        1  17.377248\n",
       "2        2  17.068167\n",
       "3        3  17.087143\n",
       "4        4  16.853126"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens[['age', 'cluster']].groupby(['cluster'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters do not differ in terms of ages very much. There is no immediate relation between age and interest clusters. Now, let’s look at the female contribution to each cluster. How? Which column to you have to use instead of age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.777703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.772329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.893979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.870130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.906716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster    female\n",
       "0        0  0.777703\n",
       "1        1  0.772329\n",
       "2        2  0.893979\n",
       "3        3  0.870130\n",
       "4        4  0.906716"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens[['female', 'cluster']].groupby(['cluster'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, 74 per cent of the SNS's users are female. That’s why they contribute so much to each cluster. Can you see the cluster that has the most female users? Do you know why? Look back to the earlier analysis of the interests linked to the clusters ...\n",
    "\n",
    "You can check for the average number of friends per cluster now. Just define the target of the aggregation per cluster as friends instead of female or age in the expressions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27.636140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32.457096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>37.134872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31.831672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41.390356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster    friends\n",
       "0        0  27.636140\n",
       "1        1  32.457096\n",
       "2        2  37.134872\n",
       "3        3  31.831672\n",
       "4        4  41.390356"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teens[['friends', 'cluster']].groupby(['cluster'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the differences are stronger. We suspect that the number of friends played a key role in assigning the clusters. That’s the nature of a social network, I guess. \n",
    "\n",
    "We have now completed our exercises on clustering and understanding political and social communities. For today, we have just one more important question to answer. How do we get access to the kind of data we worked on today? The teens dataset stemmed from a research project in sociology published online, while the US Senate voting behaviour was downloaded from US government websites. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "The web has become a unique source of data for social analysis. Munzert et al. (2014) in their book on 'Automated data collection (...). A practical guide to web scraping and text mining' (John Wiley & Sons) emphasize in the Introduction that 'the rapid growth of the World Wide Web over the past two decades tremendously changed the way we share, collect, and publish data. Firms, public institutions, and private users provide every imaginable type of information and new channels of communication generate vast amounts of data on human behavior. What was once a fundamental problem for the social sciences — the scarcity and inaccessibility of observations — is quickly turning into an abundance of data. This turn of events does not come without problems. (…), traditional techniques for collecting and analyzing data may no longer suffice to overcome the tangled masses of data.' (p. XV). \n",
    "\n",
    "In short, we can find lots of data on the web. A big problem with web data is, however, that it is often inconsistent and heterogeneous. To get access to it, one often has to visit multiple web sites and assemble their data together. Finally, the data is generally published without reuse in mind, which implies that the data can be of low quality. That said, the web is so vast that it still provides an often overwhelming source of exciting data. \n",
    "\n",
    "Let's take a look at how we can access web data in general by scraping web sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"90%\" height=\"90%\" controls src=\"img-videos/Session3.mp4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to our first example of political communities, we will scrape data on the current composition of the US Senate from Wikipedia. \n",
    "\n",
    "This can be a complex task and requires additional libraries. But in this case, we can rely on Pandas directly with its read_html function that does all the hard work for you. Check it at https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html.\n",
    "\n",
    "All the content on the web is presented to us in a language called HyperText Markup Language (HTML; https://en.wikipedia.org/wiki/HTML). HTML is of course a way of presenting content on the web in a universal way. It also contains so-called hyperlinks that let you jump from web content to web content. \n",
    "\n",
    "If you are interested in the further details of HTML, why not take some time now to visit the excellent http://www.w3schools.com/html/, which contains a lot of practical exercises to learn everything about HTML and other web technologies. \n",
    "\n",
    "Each document on the web is identified by a URL. We set the url to the wikipedia page of current US senators and run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "#Run the code below\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Current_members_of_the_United_States_Senate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the read_html function of Pandas, we can read in the web content behind the URL. However, if you check the documentation you need to provide Pandas with further details.\n",
    "\n",
    "Unfortunately, web content in HTML format is not very structured and often simply chaotic. We would like to download only the table of the page of current US Senators and need to find a so-called 'match' for read_html to choose that table from the HTML document. \n",
    "\n",
    "Fortunately, for us there are many existing strategies to determine exactly the HTML element we would like to select. I looked for specific names in the table that are not repeated in the rest of the wiki page. Run: `senator_wiki = pd.read_html('https://en.wikipedia.org/wiki/List_of_current_United_States_senators', match = 'Richard Shelby')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "senator_wiki = pd.read_html('https://en.wikipedia.org/wiki/List_of_current_United_States_senators', match = 'Richard Shelby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it all worked as it should run the cell below to create our senators dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Portrait</th>\n",
       "      <th>Senator</th>\n",
       "      <th>Party</th>\n",
       "      <th>Party.1</th>\n",
       "      <th>Born</th>\n",
       "      <th>Occupation(s)</th>\n",
       "      <th>Previous electiveoffice(s)</th>\n",
       "      <th>Education</th>\n",
       "      <th>Assumed office</th>\n",
       "      <th>Term up</th>\n",
       "      <th>Residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Republican[d]</td>\n",
       "      <td>(age 87)</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>U.S. HouseAlabama Senate</td>\n",
       "      <td>University of Alabama (BA, LLB) Birmingham Sch...</td>\n",
       "      <td>January 3, 1987</td>\n",
       "      <td>2022</td>\n",
       "      <td>Tuscaloosa[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tommy Tuberville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Republican</td>\n",
       "      <td>(age 67)</td>\n",
       "      <td>College football coachPartner, investment mana...</td>\n",
       "      <td>None</td>\n",
       "      <td>Southern Arkansas University (BS)</td>\n",
       "      <td>January 3, 2021</td>\n",
       "      <td>2026</td>\n",
       "      <td>Auburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisa Murkowski</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Republican</td>\n",
       "      <td>(age 64)</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Alaska House of Representatives</td>\n",
       "      <td>Georgetown University (AB) Willamette Universi...</td>\n",
       "      <td>December 20, 2002[e]</td>\n",
       "      <td>2022</td>\n",
       "      <td>Girdwood[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dan Sullivan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Republican</td>\n",
       "      <td>(age 57)</td>\n",
       "      <td>U.S. Marine Corps officerLawyerAssistant Secre...</td>\n",
       "      <td>Alaska Attorney General</td>\n",
       "      <td>Harvard University (AB) Georgetown University ...</td>\n",
       "      <td>January 3, 2015</td>\n",
       "      <td>2026</td>\n",
       "      <td>Anchorage[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyrsten Sinema</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>(age 45)</td>\n",
       "      <td>Social workerPolitical activistLawyerCollege l...</td>\n",
       "      <td>U.S. HouseArizona SenateArizona House of Repre...</td>\n",
       "      <td>Brigham Young University (BA) Arizona State Un...</td>\n",
       "      <td>January 3, 2019</td>\n",
       "      <td>2024</td>\n",
       "      <td>Phoenix[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Portrait           Senator  Party        Party.1      Born  \\\n",
       "0  Alabama       NaN    Richard Shelby    NaN  Republican[d]  (age 87)   \n",
       "1  Alabama       NaN  Tommy Tuberville    NaN     Republican  (age 67)   \n",
       "2   Alaska       NaN    Lisa Murkowski    NaN     Republican  (age 64)   \n",
       "3   Alaska       NaN      Dan Sullivan    NaN     Republican  (age 57)   \n",
       "4  Arizona       NaN    Kyrsten Sinema    NaN     Democratic  (age 45)   \n",
       "\n",
       "                                       Occupation(s)  \\\n",
       "0                                             Lawyer   \n",
       "1  College football coachPartner, investment mana...   \n",
       "2                                             Lawyer   \n",
       "3  U.S. Marine Corps officerLawyerAssistant Secre...   \n",
       "4  Social workerPolitical activistLawyerCollege l...   \n",
       "\n",
       "                          Previous electiveoffice(s)  \\\n",
       "0                           U.S. HouseAlabama Senate   \n",
       "1                                               None   \n",
       "2                    Alaska House of Representatives   \n",
       "3                            Alaska Attorney General   \n",
       "4  U.S. HouseArizona SenateArizona House of Repre...   \n",
       "\n",
       "                                           Education        Assumed office  \\\n",
       "0  University of Alabama (BA, LLB) Birmingham Sch...       January 3, 1987   \n",
       "1                  Southern Arkansas University (BS)       January 3, 2021   \n",
       "2  Georgetown University (AB) Willamette Universi...  December 20, 2002[e]   \n",
       "3  Harvard University (AB) Georgetown University ...       January 3, 2015   \n",
       "4  Brigham Young University (BA) Arizona State Un...       January 3, 2019   \n",
       "\n",
       "   Term up      Residence  \n",
       "0     2022  Tuscaloosa[2]  \n",
       "1     2026         Auburn  \n",
       "2     2022    Girdwood[3]  \n",
       "3     2026   Anchorage[4]  \n",
       "4     2024     Phoenix[5]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keep cell\n",
    "senators = senator_wiki[0]\n",
    "senators.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the data is already of fairly good quality, but we still need to clean the data a bit.\n",
    "\n",
    "Let's do some basic cleaning, where we ignore the strange textual errors and focus on the various columns that require direct attention. Please:\n",
    "\n",
    "(1) Create a 'Party' column from whatever name read_html has given that column. In my case, it was called Party.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "senators['Party'] = senators['Party.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Make sure that the 'Term up' is of type int.\n",
    "\n",
    "Transfrom the column 'Term up' into an integer column with `senators['Term up'] = senators['Term up'].astype(int)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "senators['Term up'] = senators['Term up'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Clean the column 'Born' to only contain the numerical age and rename it to 'Age'.\n",
    "\n",
    "As you can see the column Born contains the age of the senator, which we would like to extract from the string. As far as we can see these are the two digits in an otherwise string of letters. So, in (age 87) it is 87. To extract the 87, we can use regular expressions with Pandas. Take a look at https://www.dataquest.io/blog/regular-expressions-data-scientists/. We need the str.extract function https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html, which is very powerful. Run `senators['Age'] = senators['Born'].str.extract(r'.*(\\d\\d)')`.\n",
    "\n",
    "The expression with extract says to read (r) all characters in the string (.*) and look for two digits (\\d\\d) to return these. Regular expressions require some practice and trial and error in my experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "senators['Age'] = senators['Born'].str.extract(r'.*(\\d\\d)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Create a 'Years in Office' column that uses the information in 'Assumed office' to calculate how long the senator has served. Make sure that this column is of type int.\n",
    "\n",
    "We first need to know which year we are currently in. We will use this to calculate the years left in office. We can use the datetime library and its now() function. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keep cell\n",
    "import datetime\n",
    "year_ = datetime.datetime.now().year\n",
    "year_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The years in the office of a senator can be calculated by subtracting fro year_ the year when the office was assumed. We can use our regular expression knowledge and simply look for the strings which are four consecutive numbers (\\d\\d\\d\\d) and return those. Type in `senators['Years in Office'] = year_ - senators['Assumed office'].str.extract(r'.*,.*(\\d\\d\\d\\d).*').astype(int)`. Observe that we use astype(int) to make the extracted string into an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "senators['Years in Office'] = year_ - senators['Assumed office'].str.extract(r'.*,.*(\\d\\d\\d\\d).*').astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import datetime\n",
    "year_ = datetime.datetime.now().year\n",
    "\n",
    "senators['Party'] = senators['Party.1']\n",
    "senators['Age'] = senators['Born'].str.extract(r'.*(\\d\\d)')\n",
    "senators['Years in Office'] = year_ - senators['Assumed office'].str.extract(r'.*,.*(\\d\\d\\d\\d).*').astype(int)\n",
    "senators['Term up'] = senators['Term up'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's delete all unnecessary columns that you now changed such as 'Born' and 'Party.1'. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-94aa654683dd>:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  senators.drop(['Party.1', 'Born'], 1, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Portrait</th>\n",
       "      <th>Senator</th>\n",
       "      <th>Party</th>\n",
       "      <th>Occupation(s)</th>\n",
       "      <th>Previous electiveoffice(s)</th>\n",
       "      <th>Education</th>\n",
       "      <th>Assumed office</th>\n",
       "      <th>Term up</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Age</th>\n",
       "      <th>Years in Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>Republican[d]</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>U.S. HouseAlabama Senate</td>\n",
       "      <td>University of Alabama (BA, LLB) Birmingham Sch...</td>\n",
       "      <td>January 3, 1987</td>\n",
       "      <td>2022</td>\n",
       "      <td>Tuscaloosa[2]</td>\n",
       "      <td>87</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tommy Tuberville</td>\n",
       "      <td>Republican</td>\n",
       "      <td>College football coachPartner, investment mana...</td>\n",
       "      <td>None</td>\n",
       "      <td>Southern Arkansas University (BS)</td>\n",
       "      <td>January 3, 2021</td>\n",
       "      <td>2026</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisa Murkowski</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Alaska House of Representatives</td>\n",
       "      <td>Georgetown University (AB) Willamette Universi...</td>\n",
       "      <td>December 20, 2002[e]</td>\n",
       "      <td>2022</td>\n",
       "      <td>Girdwood[3]</td>\n",
       "      <td>64</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dan Sullivan</td>\n",
       "      <td>Republican</td>\n",
       "      <td>U.S. Marine Corps officerLawyerAssistant Secre...</td>\n",
       "      <td>Alaska Attorney General</td>\n",
       "      <td>Harvard University (AB) Georgetown University ...</td>\n",
       "      <td>January 3, 2015</td>\n",
       "      <td>2026</td>\n",
       "      <td>Anchorage[4]</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyrsten Sinema</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Social workerPolitical activistLawyerCollege l...</td>\n",
       "      <td>U.S. HouseArizona SenateArizona House of Repre...</td>\n",
       "      <td>Brigham Young University (BA) Arizona State Un...</td>\n",
       "      <td>January 3, 2019</td>\n",
       "      <td>2024</td>\n",
       "      <td>Phoenix[5]</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Portrait           Senator          Party  \\\n",
       "0  Alabama       NaN    Richard Shelby  Republican[d]   \n",
       "1  Alabama       NaN  Tommy Tuberville     Republican   \n",
       "2   Alaska       NaN    Lisa Murkowski     Republican   \n",
       "3   Alaska       NaN      Dan Sullivan     Republican   \n",
       "4  Arizona       NaN    Kyrsten Sinema     Democratic   \n",
       "\n",
       "                                       Occupation(s)  \\\n",
       "0                                             Lawyer   \n",
       "1  College football coachPartner, investment mana...   \n",
       "2                                             Lawyer   \n",
       "3  U.S. Marine Corps officerLawyerAssistant Secre...   \n",
       "4  Social workerPolitical activistLawyerCollege l...   \n",
       "\n",
       "                          Previous electiveoffice(s)  \\\n",
       "0                           U.S. HouseAlabama Senate   \n",
       "1                                               None   \n",
       "2                    Alaska House of Representatives   \n",
       "3                            Alaska Attorney General   \n",
       "4  U.S. HouseArizona SenateArizona House of Repre...   \n",
       "\n",
       "                                           Education        Assumed office  \\\n",
       "0  University of Alabama (BA, LLB) Birmingham Sch...       January 3, 1987   \n",
       "1                  Southern Arkansas University (BS)       January 3, 2021   \n",
       "2  Georgetown University (AB) Willamette Universi...  December 20, 2002[e]   \n",
       "3  Harvard University (AB) Georgetown University ...       January 3, 2015   \n",
       "4  Brigham Young University (BA) Arizona State Un...       January 3, 2019   \n",
       "\n",
       "   Term up      Residence Age  Years in Office  \n",
       "0     2022  Tuscaloosa[2]  87               34  \n",
       "1     2026         Auburn  67                0  \n",
       "2     2022    Girdwood[3]  64               19  \n",
       "3     2026   Anchorage[4]  57                6  \n",
       "4     2024     Phoenix[5]  45                2  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keep cell\n",
    "senators.drop(['Party.1', 'Born'], 1, inplace = True)\n",
    "senators.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before, we now would like to ask questions against the dataset and explore it. \n",
    "\n",
    "In particular, we would like to understand the pressure on parties during the next election for the US Senate. At the time of writing, these were the 2022 elections for Congress. We could now reuse some of the strategies for exploring data in Pandas we have learned about earlier.\n",
    "\n",
    "Let's look into the questions when their seats are up again for the senators. Create a new dataframe with copy() from senators that only contains the 'Senator', 'State', 'Party', 'Occupation(s)', 'Years in Office' and 'Term up' columns. Call it senators_seatup.\n",
    "\n",
    "Run `senators_seatup = senators[['Senator', 'State', 'Party', 'Occupation(s)', 'Years in Office', 'Term up']].copy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "senators_seatup = senators[['Senator', 'State', 'Party', 'Occupation(s)', 'Years in Office', 'Term up']].copy()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first couple of rows of the data, and you will only find those columns you selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Senator</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Occupation(s)</th>\n",
       "      <th>Years in Office</th>\n",
       "      <th>Term up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Republican[d]</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>34</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tommy Tuberville</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Republican</td>\n",
       "      <td>College football coachPartner, investment mana...</td>\n",
       "      <td>0</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa Murkowski</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>19</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dan Sullivan</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Republican</td>\n",
       "      <td>U.S. Marine Corps officerLawyerAssistant Secre...</td>\n",
       "      <td>6</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kyrsten Sinema</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Social workerPolitical activistLawyerCollege l...</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Senator    State          Party  \\\n",
       "0    Richard Shelby  Alabama  Republican[d]   \n",
       "1  Tommy Tuberville  Alabama     Republican   \n",
       "2    Lisa Murkowski   Alaska     Republican   \n",
       "3      Dan Sullivan   Alaska     Republican   \n",
       "4    Kyrsten Sinema  Arizona     Democratic   \n",
       "\n",
       "                                       Occupation(s)  Years in Office  Term up  \n",
       "0                                             Lawyer               34     2022  \n",
       "1  College football coachPartner, investment mana...                0     2026  \n",
       "2                                             Lawyer               19     2022  \n",
       "3  U.S. Marine Corps officerLawyerAssistant Secre...                6     2026  \n",
       "4  Social workerPolitical activistLawyerCollege l...                2     2024  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senators_seatup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the types? Do you need to change them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Senator            object\n",
       "State              object\n",
       "Party              object\n",
       "Occupation(s)      object\n",
       "Years in Office     int64\n",
       "Term up             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senators_seatup.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my case, they were ok. They are only strings and ints - all in the right place.\n",
    "\n",
    "Next, we would like to determine the next time an election is held. This information is in the 'Term up' column and there logically the smallest value. Assign that value to a variable next_election and pring it out by running \n",
    "```\n",
    "next_election = senators_seatup['Term up'].min()\n",
    "next_election\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_election = senators_seatup['Term up'].min()\n",
    "next_election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we select the rows/observations that are relevant for the next election and filter the senators_seatup rows with next_election. Assign the results to senators_seatup_next. Do you remember how to do this? If not check https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html for a quick reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "strip.white": true
   },
   "outputs": [],
   "source": [
    "senators_seatup_next = senators_seatup[senators_seatup['Term up'] == next_election]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display all the senators whose seats are up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Senator</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Occupation(s)</th>\n",
       "      <th>Years in Office</th>\n",
       "      <th>Term up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Republican[d]</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>34</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa Murkowski</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>19</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mark Kelly</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>U.S. Navy officerNASA AstronautFounder, Americ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>John Boozman</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Optometrist</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alex Padilla</td>\n",
       "      <td>California</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Michael Bennet</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>LawyerInvestment company executiveDenver Publi...</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Richard Blumenthal</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Marine Corps Reserve SergeantSenate stafferLaw...</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Marco Rubio</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Raphael Warnock</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Pastor</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Brian Schatz</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>TeacherNonprofit organization executive</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mike Crapo</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>22</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tammy Duckworth</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Army National Guard OfficerCoordinator, Center...</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Todd Young</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Marine Corps OfficerProfessorConsultantLawyer</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chuck Grassley</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>Republican</td>\n",
       "      <td>FarmerCollege professor</td>\n",
       "      <td>40</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jerry Moran</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>Republican</td>\n",
       "      <td>BankerLawyer</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Rand Paul</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Physician specializing in Ophthalmology</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>John Kennedy</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Magazine editorLawyerProfessorStaff of Louisia...</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Chris Van Hollen</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>U.S. Senate staff memberMaryland Governor's le...</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Roy Blunt</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Republican</td>\n",
       "      <td>University president</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Catherine Cortez Masto</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Maggie Hassan</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Chuck Schumer</td>\n",
       "      <td>New York</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>22</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Richard Burr</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Sales managerNonprofit organization executive</td>\n",
       "      <td>16</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>John Hoeven</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Banker</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Rob Portman</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Republican</td>\n",
       "      <td>LawyerU.S. Trade RepresentativeDirector of the...</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>James Lankford</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Republican</td>\n",
       "      <td>TeacherNonprofit program director</td>\n",
       "      <td>6</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Ron Wyden</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>TeacherNonprofit organization executive</td>\n",
       "      <td>25</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Pat Toomey</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Currency traderRestaurant owner</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Tim Scott</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Insurance agentFinancial adviser</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>John Thune</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Nonprofit organization executiveState Railroad...</td>\n",
       "      <td>16</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Mike Lee</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Republican</td>\n",
       "      <td>LawyerGovernor's general counselAssistant Unit...</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Patrick Leahy</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>46</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Patty Murray</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>TeacherLobbyist</td>\n",
       "      <td>28</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ron Johnson</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Republican</td>\n",
       "      <td>AccountantCorporate executive</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Senator           State          Party  \\\n",
       "0           Richard Shelby         Alabama  Republican[d]   \n",
       "2           Lisa Murkowski          Alaska     Republican   \n",
       "5               Mark Kelly         Arizona     Democratic   \n",
       "6             John Boozman        Arkansas     Republican   \n",
       "9             Alex Padilla      California     Democratic   \n",
       "10          Michael Bennet        Colorado     Democratic   \n",
       "12      Richard Blumenthal     Connecticut     Democratic   \n",
       "16             Marco Rubio         Florida     Republican   \n",
       "19         Raphael Warnock         Georgia     Democratic   \n",
       "20            Brian Schatz          Hawaii     Democratic   \n",
       "22              Mike Crapo           Idaho     Republican   \n",
       "25         Tammy Duckworth        Illinois     Democratic   \n",
       "26              Todd Young         Indiana     Republican   \n",
       "28          Chuck Grassley            Iowa     Republican   \n",
       "30             Jerry Moran          Kansas     Republican   \n",
       "33               Rand Paul        Kentucky     Republican   \n",
       "35            John Kennedy       Louisiana     Republican   \n",
       "39        Chris Van Hollen        Maryland     Democratic   \n",
       "48               Roy Blunt        Missouri     Republican   \n",
       "54  Catherine Cortez Masto          Nevada     Democratic   \n",
       "57           Maggie Hassan   New Hampshire     Democratic   \n",
       "62           Chuck Schumer        New York     Democratic   \n",
       "64            Richard Burr  North Carolina     Republican   \n",
       "66             John Hoeven    North Dakota     Republican   \n",
       "69             Rob Portman            Ohio     Republican   \n",
       "71          James Lankford        Oklahoma     Republican   \n",
       "72               Ron Wyden          Oregon     Democratic   \n",
       "75              Pat Toomey    Pennsylvania     Republican   \n",
       "79               Tim Scott  South Carolina     Republican   \n",
       "80              John Thune    South Dakota     Republican   \n",
       "86                Mike Lee            Utah     Republican   \n",
       "88           Patrick Leahy         Vermont     Democratic   \n",
       "92            Patty Murray      Washington     Democratic   \n",
       "96             Ron Johnson       Wisconsin     Republican   \n",
       "\n",
       "                                        Occupation(s)  Years in Office  \\\n",
       "0                                              Lawyer               34   \n",
       "2                                              Lawyer               19   \n",
       "5   U.S. Navy officerNASA AstronautFounder, Americ...                1   \n",
       "6                                         Optometrist               10   \n",
       "9                                            Engineer                0   \n",
       "10  LawyerInvestment company executiveDenver Publi...               12   \n",
       "12  Marine Corps Reserve SergeantSenate stafferLaw...               10   \n",
       "16                                             Lawyer               10   \n",
       "19                                             Pastor                0   \n",
       "20            TeacherNonprofit organization executive                9   \n",
       "22                                             Lawyer               22   \n",
       "25  Army National Guard OfficerCoordinator, Center...                4   \n",
       "26      Marine Corps OfficerProfessorConsultantLawyer                4   \n",
       "28                            FarmerCollege professor               40   \n",
       "30                                       BankerLawyer               10   \n",
       "33            Physician specializing in Ophthalmology               10   \n",
       "35  Magazine editorLawyerProfessorStaff of Louisia...                4   \n",
       "39  U.S. Senate staff memberMaryland Governor's le...                4   \n",
       "48                               University president               10   \n",
       "54                                             Lawyer                4   \n",
       "57                                             Lawyer                4   \n",
       "62                                             Lawyer               22   \n",
       "64      Sales managerNonprofit organization executive               16   \n",
       "66                                             Banker               10   \n",
       "69  LawyerU.S. Trade RepresentativeDirector of the...               10   \n",
       "71                  TeacherNonprofit program director                6   \n",
       "72            TeacherNonprofit organization executive               25   \n",
       "75                    Currency traderRestaurant owner               10   \n",
       "79                   Insurance agentFinancial adviser                8   \n",
       "80  Nonprofit organization executiveState Railroad...               16   \n",
       "86  LawyerGovernor's general counselAssistant Unit...               10   \n",
       "88                                             Lawyer               46   \n",
       "92                                    TeacherLobbyist               28   \n",
       "96                      AccountantCorporate executive               10   \n",
       "\n",
       "    Term up  \n",
       "0      2022  \n",
       "2      2022  \n",
       "5      2022  \n",
       "6      2022  \n",
       "9      2022  \n",
       "10     2022  \n",
       "12     2022  \n",
       "16     2022  \n",
       "19     2022  \n",
       "20     2022  \n",
       "22     2022  \n",
       "25     2022  \n",
       "26     2022  \n",
       "28     2022  \n",
       "30     2022  \n",
       "33     2022  \n",
       "35     2022  \n",
       "39     2022  \n",
       "48     2022  \n",
       "54     2022  \n",
       "57     2022  \n",
       "62     2022  \n",
       "64     2022  \n",
       "66     2022  \n",
       "69     2022  \n",
       "71     2022  \n",
       "72     2022  \n",
       "75     2022  \n",
       "79     2022  \n",
       "80     2022  \n",
       "86     2022  \n",
       "88     2022  \n",
       "92     2022  \n",
       "96     2022  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senators_seatup_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. Let's next group observations together to gain composite insights. Let's look at the senators per US state. Use senators_seatup_next and the columns 'State' and 'Term up' to display the number of terms that are up in the next election. Run `senators_seatup_next[['State', 'Term up']].groupby(['State'], as_index=False).count()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Term up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Washington</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Term up\n",
       "0          Alabama        1\n",
       "1           Alaska        1\n",
       "2          Arizona        1\n",
       "3         Arkansas        1\n",
       "4       California        1\n",
       "5         Colorado        1\n",
       "6      Connecticut        1\n",
       "7          Florida        1\n",
       "8          Georgia        1\n",
       "9           Hawaii        1\n",
       "10           Idaho        1\n",
       "11        Illinois        1\n",
       "12         Indiana        1\n",
       "13            Iowa        1\n",
       "14          Kansas        1\n",
       "15        Kentucky        1\n",
       "16       Louisiana        1\n",
       "17        Maryland        1\n",
       "18        Missouri        1\n",
       "19          Nevada        1\n",
       "20   New Hampshire        1\n",
       "21        New York        1\n",
       "22  North Carolina        1\n",
       "23    North Dakota        1\n",
       "24            Ohio        1\n",
       "25        Oklahoma        1\n",
       "26          Oregon        1\n",
       "27    Pennsylvania        1\n",
       "28  South Carolina        1\n",
       "29    South Dakota        1\n",
       "30            Utah        1\n",
       "31         Vermont        1\n",
       "32      Washington        1\n",
       "33       Wisconsin        1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senators_seatup_next[['State', 'Term up']].groupby(['State'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least in 2021, there were quite a few senators up for re-election. How does it look for you? \n",
    "\n",
    "Finally, we wanted to look into the election challenges per party. Select 'Party' and 'Term up' and group by party to display the results with count(), please. You can do it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Term up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republican</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Republican[d]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Party  Term up\n",
       "0     Democratic       14\n",
       "1     Republican       19\n",
       "2  Republican[d]        1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senators_seatup_next[['Party', 'Term up']].groupby(['Party'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Republicans had far more seats to lose in 2021. You might see different results depending on the election you look at. Let's try and find out a little bit more about the senators up for re-election.  What is their median time in office if you group them by party? \n",
    "\n",
    "The agg function is the last very powerful Pandas tool we introduce: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html. Used together with groupby on party we can apply easily several functions like median and count in our case: `senators_seatup_next[['Party', 'Years in Office']].groupby(['Party']).agg(['median', 'count'])`. You should read this expression as a pipleine, where you first select two columns from senators_seatup_next, then group by one of the columns and aggregate the values with two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "strip.white": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Years in Office</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>median</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Party</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Democratic</th>\n",
       "      <td>6.5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Republican</th>\n",
       "      <td>10.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Republican[d]</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Years in Office      \n",
       "                       median count\n",
       "Party                              \n",
       "Democratic                6.5    14\n",
       "Republican               10.0    19\n",
       "Republican[d]            34.0     1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senators_seatup_next[['Party', 'Years in Office']].groupby(['Party']).agg(['median', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2021, the Democrats had much younger senators who had also served much shorter, which might indicate that they had much less time to secure the seat for their party. Your results will of course depend on the year you are looking at but can you find similar patterns? \n",
    "\n",
    "That's it for today's analysis of social communities with the additional bonus of learning a little bit about how to harvest data from the web, which is already advanced stuff. Thank you ..."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,message,strip.white,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}